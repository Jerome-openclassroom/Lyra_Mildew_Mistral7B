<img src="https://upload.wikimedia.org/wikipedia/en/c/c3/Flag_of_France.svg" width="100px" height="auto" />

# Lyra_Mildew_Mistral7B  
ModÃ¨le LoRA pour lâ€™Ã©valuation du risque de mildiou de la vigne  
â¡ï¸ [English version / Version anglaise](./README_En.md)

---

# ğŸ·ï¸ Badges

![Mistral AI](https://img.shields.io/badge/Model-Mistral%207B-blue.svg)
![Europe](https://img.shields.io/badge/Origin-Europe-blue)
[![HuggingFace](https://img.shields.io/badge/HuggingFace-Model-yellow.svg)](https://huggingface.co/jeromex1/lyra_Mildew_mistral7B_LoRA)

---

# ğŸŒ¿ PrÃ©sentation gÃ©nÃ©rale

**Lyra_Mildew_Mistral7B** est un modÃ¨le **LoRA** basÃ© sur **Mistral 7B**, spÃ©cialisÃ© dans la **prÃ©diction du risque de mildiou de la vigne (*Plasmopara viticola*)**, Ã  partir de variables agro-mÃ©tÃ©orologiques standard :

- `Stade_phenologique`
- `Humectation_continue` (h)
- `Temperature_moyenne` (Â°C)
- `Pluie_24h` (mm)
- `Inoculum` (0.1 Ã  0.9)

Le modÃ¨le retourne un format clair et structurÃ© :

```
Risque : [faible / moyen / Ã©levÃ©]
Recommandation : [1 Ã  3 phrases, spÃ©cifique et actionnable]
```

Ce projet sâ€™inscrit dans une dÃ©marche dâ€™**IA appliquÃ©e Ã  lâ€™agronomie**, adaptÃ©e aux besoins dâ€™aide Ã  la dÃ©cision dans les systÃ¨mes de production viticole.

---

# ğŸ“ Arborescence du dÃ©pÃ´t

```
â”œâ”€â”€ README.md                         # Documentation complÃ¨te en franÃ§ais
â”œâ”€â”€ README_En.md                      # Documentation anglaise (rÃ©sumÃ© du projet)
â”‚
â”œâ”€â”€ code_prompt/
â”‚   â”œâ”€â”€ dataset_building_rules.txt    # RÃ¨gles guidant la gÃ©nÃ©ration du dataset
â”‚   â”œâ”€â”€ Lyra_Mildew_7B.py             # Script Python d'entraÃ®nement LoRA
â”‚   â””â”€â”€ system_prompt.txt             # Prompt systÃ¨me utilisÃ© pour le modÃ¨le
â”‚
â”œâ”€â”€ controle_dataset/
â”‚   â”œâ”€â”€ quality_control_En.md         # Rapport QC dataset (anglais)
â”‚   â”œâ”€â”€ quality_control_Fr.md         # Rapport QC dataset (franÃ§ais)
â”‚   â”œâ”€â”€ moisture_statistics.png       # RÃ©partition des durÃ©es d'humectation
â”‚   â”œâ”€â”€ rain_statistics.png           # RÃ©partition du cumul de pluie
â”‚   â””â”€â”€ temperature_statistics.png    # RÃ©partition des tempÃ©ratures moyennes
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ dataset_mildiou_1500_train.jsonl       # Dataset d'entraÃ®nement (1500 lignes)
â”‚   â”œâ”€â”€ dataset_mildiou_validation_149.jsonl   # Dataset de validation (149 lignes)
â”‚   â””â”€â”€ Mildew_dataset_middle_30.jsonl         # Dataset de calibration ciblÃ©e (30 lignes)
â”‚
â”œâ”€â”€ pre_test_7B_8B/
â”‚   â”œâ”€â”€ playground_7b_8b.txt          # Batterie de prompts de test (modÃ¨les non entraÃ®nÃ©s)
â”‚   â””â”€â”€ comparaison_7B_8B.xlsx        # Tableau comparatif Mistral 7B vs 8B
```

---

# ğŸ“š Datasets utilisÃ©s

| Dataset | Taille | RÃ´le |
|--------|--------|------|
| `dataset_mildiou_1500_train.jsonl` | 1500 | EntraÃ®nement principal LoRA |
| `dataset_mildiou_validation_149.jsonl` | 149 | Validation |
| `Mildew_dataset_middle_30.jsonl` | 30 | Calibration ciblÃ©e (floraison extrÃªme) |

Les datasets utilisent un **format JSONL de type chat**, compatible Mistral et Hugging Face.

---

# âš™ï¸ HyperparamÃ¨tres dâ€™entraÃ®nement

```python
output_dir="./lyra_Mildew_LoRA"
num_train_epochs=3
per_device_train_batch_size=2
per_device_eval_batch_size=2
gradient_accumulation_steps=8
learning_rate=2e-4
fp16=True
logging_steps=10
eval_strategy="epoch"
save_strategy="epoch"
lr_scheduler_type="cosine"
warmup_ratio=0.03
weight_decay=0.0
report_to="none"
```

### ğŸ”§ Calibration spÃ©cialisÃ©e (30 lignes)
Une mini-passe supplÃ©mentaire a permis dâ€™ajuster la dÃ©tection du risque Ã©levÃ© en floraison.

**Loss (steps 1â†’4)** :  
`2.38 â†’ 1.30 â†’ 1.00 â†’ 0.90`

---

# ğŸ“Š RÃ©sultats dâ€™entraÃ®nement

| Epoch | Training Loss | Validation Loss | Entropy | Mean Token Accuracy |
|-------|---------------|-----------------|---------|----------------------|
| 1     | 0.2809        | 0.2760          | 0.2861  | 0.9200               |
| 2     | 0.2760        | 0.2722          | 0.2819  | 0.9226               |
| 3     | 0.2693        | 0.2696          | 0.2766  | 0.9233               |

**Convergence stable**, trÃ¨s faible Ã©cart train/validation.

---

# ğŸ§ª Ã‰valuation sur 12 scÃ©narios agro-mÃ©tÃ©o

Un panel de 12 situations reprÃ©sentatives (faible / moyen / Ã©levÃ©), incluant plusieurs cas limites, a Ã©tÃ© utilisÃ©.

## ğŸ¯ Taux d'exactitude

| CritÃ¨re | Score | Commentaire |
|---------|--------|-------------|
| Exactitude stricte | **75 %** | Correspondance exacte |
| Aide Ã  la dÃ©cision | **83 %** | SurÃ©valuations prudentes acceptÃ©es |
| Exactitude agronomique rÃ©aliste | **â‰ˆ 92 %** | Le modÃ¨le Ã©vite les sous-estimations, ce qui est recherchÃ© |

Le modÃ¨le adopte une posture **prudente**, utile pour limiter les faux nÃ©gatifs dans un contexte phytosanitaire.

---

# ğŸŒ¦ï¸ Ressources utilisÃ©es (Google Colab Pro)

- GPU : **A100 40GB**  
- VRAM utilisÃ©e : **20.87 GB**  
- RAM utilisÃ©e : **9.20 GB**  
- Temps d'exÃ©cution : quelques minutes pour la calibration

---

# ğŸ”— Lien vers le modÃ¨le Hugging Face

ğŸ‘‰ https://huggingface.co/jeromex1/lyra_Mildew_mistral7B_LoRA

---

# ğŸš€ Exemple dâ€™utilisation (Python)

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

name = "jeromex1/lyra_Mildew_mistral7B_LoRA"
tok = AutoTokenizer.from_pretrained(name)
model = AutoModelForCausalLM.from_pretrained(name)

messages = [
    {"role": "system", "content": "Tu es un agronome spÃ©cialisÃ© dans le mildiouâ€¦"},
    {"role": "user", "content": "Stade_phenologique: floraison
Humectation_continue: 12
Temperature_moyenne: 20
Pluie_24h: 10
Inoculum: 0.7"}
]

text = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tok(text, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=120)
print(tok.decode(outputs[0], skip_special_tokens=True))
```

---

# âš ï¸ Disclaimer

Ce modÃ¨le constitue une **aide Ã  la dÃ©cision**.  
Il ne remplace pas lâ€™expertise agronomique, les observations de terrain ou les rÃ©glementations locales concernant lâ€™usage de produits phytosanitaires.

---

# ğŸ“„ Licence

Usage autorisÃ© pour la recherche, l'enseignement, la dÃ©monstration et lâ€™expÃ©rimentation agronomique non-commerciale.
